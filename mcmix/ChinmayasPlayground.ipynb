{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08537866",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f35a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "\n",
    "import sys\n",
    "# setting path\n",
    "sys.path.append('../core')\n",
    "import os\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"10\"\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#bread and butter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#machine learning library\n",
    "import sklearn\n",
    "import sklearn.manifold\n",
    "import sklearn.cluster\n",
    "import sklearn.decomposition\n",
    "\n",
    "#statistics\n",
    "import scipy\n",
    "from scipy.stats import rankdata, norm\n",
    "\n",
    "import numba\n",
    "from numba import jit, njit\n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import cvxpy as cp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "#import numpy as tnp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import dfply\n",
    "# from dfply import *\n",
    "# import ray\n",
    "# import datetime\n",
    "\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import confound_mdp\n",
    "import confound_ope\n",
    "import confound_env\n",
    "import copy\n",
    "\n",
    "from subspace import *\n",
    "from clustering import *\n",
    "from emalg import *\n",
    "from helpers import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('matplotlibrc')\n",
    "import os\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc61fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a single environment\n",
    "\n",
    "\n",
    "envs = []\n",
    "# each row:\n",
    "#   [mdp , pi_b, pi_e, horizon, gamma, nStates, nActions, term]\n",
    "\n",
    "\n",
    "horizon = 100 #18\n",
    "\n",
    "#, slip = 0.04, confound_weight=0.6\n",
    "pi_b, P, R, x_dist, u_dist, gamma = confound_env.gridworld_opetools(horizon = horizon, slip = 0.04, \n",
    "                                                                    confound_weight=0.1, small=False, soft=True)\n",
    "\n",
    "# R = -1*R\n",
    "gridworld = confound_mdp.ConfoundMDP(P, R, x_dist, u_dist, gamma)\n",
    "\n",
    "nStates = P.shape[2]\n",
    "nActions = P.shape[1]\n",
    "\n",
    "# Generate evaluation policy\n",
    "pi_e = np.zeros((nStates, nActions))\n",
    "for i in range(nStates):\n",
    "    pi_e[i] = [0.4, 0.1, 0.4, 0.1]\n",
    "\n",
    "    \n",
    "envs.append([gridworld, pi_b, pi_e, horizon, gamma, nStates, nActions, -1, P, R, x_dist, u_dist, gamma])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236e1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiprocessing adjusted for Windows\n",
    "\n",
    "\n",
    "def getSamplesMultiProc(samples, mdp, pi_b, horizon, iid=True):\n",
    "    nprocs = multiprocessing.cpu_count()\n",
    "    with ProcessPoolExecutor(max_workers=nprocs, mp_context=multiprocessing.get_context('spawn')) as executor:\n",
    "        future = executor.map(collect_sample, [int(samples/nprocs) for i in range(nprocs)], repeat(copy.deepcopy(mdp)), \n",
    "                              repeat(copy.deepcopy(pi_b)), repeat(horizon), [i for i in range(nprocs)], repeat(iid))\n",
    "    dataset = np.vstack(list(future))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bdfeaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "running env with horizon 100\n",
      "value of pi_b\n",
      "-4.213761931192736\n"
     ]
    }
   ],
   "source": [
    "# Test behavior policy and obtain its value\n",
    "\n",
    "\n",
    "for mdp , pi_b, pi_e, base_horizon, gamma, nStates, nActions, term, P, R, x_dist, u_dist, gamma in [envs[-1]]:\n",
    "    \n",
    "    print(\"---\")\n",
    "    \n",
    "    print(\"running env with horizon\", horizon)\n",
    "\n",
    "    #dataset = confound_mdp.collect_sample(int(100), mdp, pi_b, horizon, iid=False)\n",
    "    #pi_b = np.array([pi_b.mean(0),pi_b.mean(0)])\n",
    "    \n",
    "    # shape num_traj, horizon, 5 - 5 means (s,a,u,s',r)\n",
    "    dataset = getSamplesMultiProc(10000, mdp, pi_b, horizon, iid=False)\n",
    "    \n",
    "    # shape num_traj*horizon, 5 \n",
    "    data = dataset.reshape((dataset.shape[0]*dataset.shape[1],5))\n",
    "    \n",
    "    # Estimate transition probability\n",
    "    Phat = confound_ope.estimate_P(dataset, mdp)\n",
    "    \n",
    "    # Estimate policy\n",
    "    pihat = confound_ope.estimate_pi(dataset, mdp)\n",
    "    \n",
    "    # Make both \n",
    "    for a in range(nActions):\n",
    "        for s in range(nStates):\n",
    "            if Phat[a,s].sum() == 0:\n",
    "                Phat[a,s,term] = 1\n",
    "            if pihat[s].sum() == 0:\n",
    "                pihat[s,:] = 1/nActions\n",
    "                \n",
    "                \n",
    "    pi_avg = pi_b[0] * u_dist[0] + pi_b[1] * u_dist[1]\n",
    "\n",
    "    # This is the actual reward_sa\n",
    "    # P(s,a,s') * R(s,a,s')\n",
    "    # R(s,a) = \\Sum_{s'} P(s,a,s') * R(s,a,s')\n",
    "    R_sa = (np.average(P, axis=0, weights=u_dist) * R).sum(axis=2).T #np.sum(R, axis=2).T #.reshape(nStates, nActions)\n",
    "    P_spsa = Phat.transpose((2, 1, 0))\n",
    "    n = data.shape[0]\n",
    "\n",
    "\n",
    "     # behavior value\n",
    "    print(\"value of pi_b\")\n",
    "    returns = confound_mdp.calc_returns(dataset, gamma, horizon)\n",
    "    print(returns.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a26fbf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the policy, Pb, and (s,a) counts\n",
    "\n",
    "from numba import njit\n",
    "#Ptrue_spsa = np.einsum('u,uasp->psa', u_dist, P)\n",
    "\n",
    "# shape S, A\n",
    "pi_bsa = np.einsum('u,usa->sa', u_dist, pi_b)\n",
    "\n",
    "# shape S (s'), S (s), A (a)\n",
    "Pb_spsa = getPb_spsa(nStates, nActions, u_dist, pi_b, pi_bsa, P)\n",
    "\n",
    "# starts from a later state (index = burnin) in every trajectory\n",
    "burnin = 10\n",
    "\n",
    "# s,a counts for each pair - shape S, A\n",
    "N_sa = getN_sa(dataset, nStates, nActions, burnin=burnin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312023cc",
   "metadata": {},
   "source": [
    "# Subspace Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54ece31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateactions = dataset[:, :, [0, 1]]\n",
    "X = stateactions.reshape(stateactions.shape[0], stateactions.shape[1]*stateactions.shape[2])\n",
    "fullX = dataset.reshape(dataset.shape[0], dataset.shape[1]*dataset.shape[2])\n",
    "\n",
    "memorder = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e30a3384",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m omegatwo \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mint\u001b[39m(horizon\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), horizon)])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m onehotsa \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstateactions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstateactions\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     10\u001b[0m onehotsaflat \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(onehotsa)\n\u001b[0;32m     11\u001b[0m onehotsa \u001b[38;5;241m=\u001b[39m onehotsa\u001b[38;5;241m.\u001b[39mreshape((onehotsa\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], onehotsa\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], nStates, nActions), order\u001b[38;5;241m=\u001b[39mmemorder)\n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "sadim = nStates*nActions # SA\n",
    "spdim = nStates # S\n",
    "\n",
    "# Determine the omega1 and omega2 segments\n",
    "omegaone = np.array([i for i in range(int(horizon/4), 2*int(horizon/4))])\n",
    "omegatwo = np.array([i for i in range(3*int(horizon/4), horizon)])\n",
    "\n",
    "# \n",
    "onehotsa = np.eye(int(np.max(stateactions))+1)[stateactions]\n",
    "onehotsaflat = copy.deepcopy(onehotsa)\n",
    "onehotsa = onehotsa.reshape((onehotsa.shape[0], onehotsa.shape[1], nStates, nActions), order=memorder)\n",
    "onehotsp = np.eye(np.max(nextstates)+1)[nextstates]\n",
    "sz = int(onehotsa.shape[0]/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814fa6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
