{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Learning the policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:43:04.067095Z",
     "start_time": "2019-04-19T16:43:04.049687Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:43:04.753547Z",
     "start_time": "2019-04-19T16:43:04.068986Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cf.counterfactual as cf\n",
    "import cf.utils as utils\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools as it\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "# Sepsis Simulator code\n",
    "from sepsisSimDiabetes.State import State\n",
    "from sepsisSimDiabetes.Action import Action\n",
    "from sepsisSimDiabetes.DataGenerator import DataGenerator\n",
    "import sepsisSimDiabetes.MDP as simulator \n",
    "\n",
    "\n",
    "import mdptoolboxSrc.mdp as mdptools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Avoid Type 3 fonts\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "figpath = \"./figs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:43:04.753547Z",
     "start_time": "2019-04-19T16:43:04.068986Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_prefix = \"main-paper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:43:04.769134Z",
     "start_time": "2019-04-19T16:43:04.755230Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1  # Note this is not the only random seed, see the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:43:04.787255Z",
     "start_time": "2019-04-19T16:43:04.770642Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "NSIMSAMPS = 1000  # Samples to draw from the simulator\n",
    "NSTEPS = 20  # Max length of each trajectory\n",
    "NCFSAMPS = 5  # Counterfactual Samples per observed sample\n",
    "DISCOUNT_Pol = 0.99 # Used for computing optimal policies\n",
    "DISCOUNT = 1 # Used for computing actual reward\n",
    "PHYS_EPSILON = 0.05 # Used for sampling using physician pol as eps greedy\n",
    "\n",
    "PROB_DIAB = 0.2\n",
    "\n",
    "# Option 1: Use bootstrapping w/replacement on the original NSIMSAMPS to estimate errors\n",
    "USE_BOOSTRAP=True\n",
    "N_BOOTSTRAP = 100\n",
    "\n",
    "# Option 2: Use repeated sampling (i.e., NSIMSAMPS fresh simulations each time) to get error bars; \n",
    "# This is done in the appendix of the paper, but not in the main paper\n",
    "N_REPEAT_SAMPLING = 1\n",
    "\n",
    "# These are properties of the simulator, do not change\n",
    "n_actions = Action.NUM_ACTIONS_TOTAL\n",
    "n_components = 2\n",
    "\n",
    "# These are added as absorbing states\n",
    "n_states_abs = State.NUM_OBS_STATES + 2\n",
    "discStateIdx = n_states_abs - 1\n",
    "deadStateIdx = n_states_abs - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition / Reward Mats for full-information vs. marginalized MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll load the transition and reward matricies from file.  Because our simulator works in \"vitals space\" according to clinical logic, we need to do some legwork to convert this to a matrix representation.  Most notably, due to the complexity of the transitions in the simulator, it is not straightforward to read out the transition matrix from the simulator code, so we estimate it using a large amount of data from each transition (see the relevant notebook `learn_mdp_paramters.ipynb`)\n",
    "\n",
    "Once we have this \"ground truth\" transition / reward matrix learned from an arbitrarily large amount of data (or rather, two transition / reward matricies, one for each value of diabetes), we will manipulate it to construct the \"observed\" transition / reward matricies used by the physician and RL policies respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:43:04.944514Z",
     "start_time": "2019-04-19T16:43:04.789044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the transition and reward matrix from file\n",
    "with open(\"./data/diab_txr_mats-replication.pkl\", \"rb\") as f:\n",
    "    mdict = pickle.load(f)\n",
    "\n",
    "tx_mat = mdict[\"tx_mat\"]\n",
    "r_mat = mdict[\"r_mat\"]\n",
    "p_mixture = np.array([1 - PROB_DIAB, PROB_DIAB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:43:05.064330Z",
     "start_time": "2019-04-19T16:43:04.946096Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import block_diag\n",
    "\n",
    "tx_mat_full = np.zeros((n_actions, State.NUM_FULL_STATES, State.NUM_FULL_STATES))\n",
    "r_mat_full = np.zeros((n_actions, State.NUM_FULL_STATES, State.NUM_FULL_STATES))\n",
    "\n",
    "for a in range(n_actions):\n",
    "    tx_mat_full[a, ...] = block_diag(tx_mat[0, a, ...], tx_mat[1, a,...])\n",
    "    r_mat_full[a, ...] = block_diag(r_mat[0, a, ...], r_mat[1, a, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T16:43:14.717995Z",
     "start_time": "2019-04-19T16:43:05.066210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 s, sys: 37.1 s, total: 55.1 s\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fullMDP = cf.MatrixMDP(tx_mat_full, r_mat_full)\n",
    "fullPol = fullMDP.policyIteration(discount=DISCOUNT_Pol, eval_type=1)\n",
    "\n",
    "physPolSoft = np.copy(fullPol)\n",
    "physPolSoft[physPolSoft == 1] = 1 - PHYS_EPSILON\n",
    "physPolSoft[physPolSoft == 0] = PHYS_EPSILON / (n_actions - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sepsisPol.npy', np.array([physPolSoft[:720], physPolSoft[720:]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
